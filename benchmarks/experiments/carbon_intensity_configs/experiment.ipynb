{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from unittest.mock import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define locations\n",
    "locations = {\n",
    "    \"us-west-2\": (43.8041334, -120.5542012),\n",
    "    \"us-west-1\": (38.8375215, -120.8958242),\n",
    "}\n",
    "\n",
    "start_date = datetime(2023, 6, 1, 0, 0, 0)\n",
    "\n",
    "end_date = datetime(2023, 6, 30, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Carbon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined and saved to ./data/carbon/us-west-2_carbon_data.json\n",
      "Data combined and saved to ./data/carbon/us-west-1_carbon_data.json\n"
     ]
    }
   ],
   "source": [
    "# Function to query the API\n",
    "def query_api(start, end, lat, lon, token):\n",
    "    url = f\"https://api-access.electricitymaps.com/free-tier/carbon-intensity/past-range?lat={lat}&lon={lon}&start={start}&end={end}\"\n",
    "    headers = {\"auth-token\": token}\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"data\"]\n",
    "    else:\n",
    "        print(f\"Error querying API: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def run():\n",
    "    for location, (latitude, longitude) in locations.items():\n",
    "        current_start = start_date - timedelta(days=7) # Start 7 days before the start date\n",
    "        combined_data = []\n",
    "\n",
    "        while current_start < end_date:\n",
    "            current_end = current_start + timedelta(days=10)\n",
    "            if current_end > end_date:\n",
    "                current_end = end_date\n",
    "            data = query_api(\n",
    "                current_start, current_end, latitude, longitude, os.environ.get(\"ELECTRICITY_MAPS_AUTH_TOKEN\")\n",
    "            )\n",
    "            combined_data.extend(data)\n",
    "            current_start = current_end + timedelta(days=1)\n",
    "\n",
    "        # Save the combined data to a file\n",
    "        output_file = f\"./data/carbon/{location}_carbon_data.json\"\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(combined_data, f)\n",
    "\n",
    "        print(f\"Data combined and saved to {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Carbon Collector Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    r = 6371.0  # Earth radius in kilometers\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return r * c\n",
    "\n",
    "def process_and_store_carbon_data_for_regions(input_file, output_folder, regions_info, current_region):\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure output directory exists\n",
    "    \n",
    "    with open(input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # For each day between start_date and end_date\n",
    "    for day in range((end_date - start_date).days + 1):\n",
    "        current_date = start_date + timedelta(days=day)\n",
    "\n",
    "        # Get all the data for the previous 7 days\n",
    "        previous_7_days_data = [entry for entry in data if datetime.strptime(entry['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ').date() >= (current_date - timedelta(days=7)).date() and datetime.strptime(entry['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ').date() < current_date.date()]\n",
    "\n",
    "        # Calculate the average carbon intensity for the previous 7 days\n",
    "        if not previous_7_days_data:\n",
    "            continue\n",
    "        overall_sum = sum(item['carbonIntensity'] for item in previous_7_days_data)\n",
    "        overall_avg = overall_sum / len(previous_7_days_data)\n",
    "\n",
    "        # Calculate the average carbon intensity for each hour of the day\n",
    "        hourly_averages = defaultdict(list)\n",
    "        for item in previous_7_days_data:\n",
    "            hour = datetime.strptime(item['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ').hour\n",
    "            hourly_averages[hour].append(item['carbonIntensity'])\n",
    "\n",
    "        hourly_avg = {hour: sum(values) / len(values) for hour, values in hourly_averages.items()}\n",
    "\n",
    "        # Calculate the distances between the regions\n",
    "        transmission_distances = {\n",
    "            region_key: calculate_distance(regions_info[current_region][0], regions_info[current_region][1], regions_info[region_key][0], regions_info[region_key][1]) for region_key in regions_info\n",
    "        }\n",
    "    \n",
    "        # Assemble the result dictionary\n",
    "        result_dict = {\n",
    "            \"averages\": {\n",
    "                \"overall\": {\"carbon_intensity\": overall_avg},\n",
    "                **{str(hour): {\"carbon_intensity\": avg} for hour, avg in hourly_avg.items()}\n",
    "            },\n",
    "            \"units\": \"gCO2eq/kWh\",\n",
    "            \"transmission_distances\": transmission_distances\n",
    "        }\n",
    "\n",
    "        # Store the result\n",
    "        day_folder = os.path.join(output_folder, current_date.strftime('%Y-%m-%d'))\n",
    "        os.makedirs(day_folder, exist_ok=True)\n",
    "        with open(os.path.join(day_folder, 'data.json'), 'w') as outfile:\n",
    "            json.dump(result_dict, outfile, indent=4)\n",
    "\n",
    "for region in locations:\n",
    "    process_and_store_carbon_data_for_regions(f\"./data/carbon/{region}_carbon_data.json\", f\"./data/collected_carbon/{region}\", locations, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Deployment Algorithm\n",
    "\n",
    "We need to run the deployment algorithm for the days between the start and end date. We will run it every day and store the results locally in files.\n",
    "Additionally, we need to provide the data collected by a specific workflow as the input to the workflow loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-x-serverless-RxvPqp3n-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
